{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "df = pd.read_csv(\"../data/dow_jones_stocks/sentiments/dataset_1/many_sentiments/AAPL.csv\")\n",
    "\n",
    "# add new column Open_before which contains the open values of the previous day\n",
    "df[\"Open_before\"] = df[\"Open\"].shift(1)\n",
    "\n",
    "# calculate the procentual change of the open value of the current day to the \n",
    "# open value of the day before\n",
    "df[\"Open_changes\"] = (df[\"Open\"] / df[\"Open_before\"]) - 1\n",
    "\n",
    "# throw out the first line which has NaN as value because of the previous shift of values \n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# reset index to start by 0\n",
    "df.index -= 1\n",
    "\n",
    "# resort data frame by start backwards\n",
    "df = df[::-1]\n",
    "\n",
    "changes = df[\"Open_changes\"]\n",
    "sentiments = df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7811, 1)\n",
      "[[ 0.00966983]\n",
      " [ 0.01732329]\n",
      " [ 0.00949477]\n",
      " ...\n",
      " [ 0.05806439]\n",
      " [ 0.01307253]\n",
      " [-0.01923098]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/normalized_sentiments_scaler.save']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# border to split in test and training data\n",
    "split_border = int(len(changes) * 0.8)\n",
    "\n",
    "# build test and training data\n",
    "train = np.array(changes[:split_border]).reshape(-1, 1)\n",
    "test = np.array(changes[split_border:]).reshape(-1, 1)\n",
    "\n",
    "print(train.shape)\n",
    "print(train)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# train the scaler with training data and smooth data\n",
    "smoothing_window_size = 2500\n",
    "for di in range(0, 5000, smoothing_window_size):\n",
    "    scaler.fit(train[di:di+smoothing_window_size,:])\n",
    "    train[di:di+smoothing_window_size,:] = scaler.transform(train[di:di+smoothing_window_size,:])\n",
    "\n",
    "# normalize the rest of the data which is len(train) - 7500\n",
    "scaler.fit(train[di+smoothing_window_size:,:])\n",
    "train[di+smoothing_window_size:,:] = scaler.transform(train[di+smoothing_window_size:,:])\n",
    "\n",
    "# normalize test data\n",
    "test = scaler.transform(test)\n",
    "\n",
    "# reshape test and train data\n",
    "train = train.reshape(-1)\n",
    "test = test.reshape(-1)\n",
    "\n",
    "# perform exponential moving average\n",
    "EMA = 0.0\n",
    "gamma = 0.1\n",
    "for ti in range(len(train)):\n",
    "    EMA = gamma * train[ti] + (1 - gamma) * EMA\n",
    "    train[ti] = EMA\n",
    "    \n",
    "# save scaler for later evaluation\n",
    "joblib.dump(scaler, '../models/normalized_sentiments_scaler.save') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(train)\n",
    "test_len = len(test)\n",
    "\n",
    "Y_train = np.array(train[:train_len-20])\n",
    "Y_test = np.array(test[:test_len-20])\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "# X data with additional value for the sentiment\n",
    "for i in range(0, len(train)- 20):\n",
    "    try:\n",
    "        to_add = train[i+1:i+21].tolist()\n",
    "        to_add.append(sentiments[i])\n",
    "        X_train.append(to_add)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for i in range(0, len(test)- 20):\n",
    "    try:\n",
    "        to_add = test[i+1:i+21].tolist()\n",
    "        to_add.append(sentiments[i])\n",
    "        X_test.append(to_add)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# reshape training data\n",
    "X_train = np.array(X_train).reshape(-1, 21, 1)\n",
    "X_test = np.array(X_test).reshape(-1, 21, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 08:21:22.638935 14180 deprecation.py:323] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1110 08:21:25.341904 14180 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W1110 08:21:25.364586 14180 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7791/7791 [==============================] - 26s 3ms/step - loss: 0.0016\n",
      "Epoch 2/10\n",
      "7791/7791 [==============================] - 21s 3ms/step - loss: 4.9303e-04\n",
      "Epoch 3/10\n",
      "7791/7791 [==============================] - 21s 3ms/step - loss: 4.3618e-04\n",
      "Epoch 4/10\n",
      "7791/7791 [==============================] - 23s 3ms/step - loss: 3.5443e-04\n",
      "Epoch 5/10\n",
      "7791/7791 [==============================] - 22s 3ms/step - loss: 3.3434e-04\n",
      "Epoch 6/10\n",
      "7791/7791 [==============================] - 26s 3ms/step - loss: 2.8887e-04\n",
      "Epoch 7/10\n",
      "7791/7791 [==============================] - 23s 3ms/step - loss: 2.5073e-04\n",
      "Epoch 8/10\n",
      "7791/7791 [==============================] - 22s 3ms/step - loss: 2.1216e-04\n",
      "Epoch 9/10\n",
      "7791/7791 [==============================] - 13s 2ms/step - loss: 2.1912e-04\n",
      "Epoch 10/10\n",
      "7791/7791 [==============================] - 11s 1ms/step - loss: 2.0014e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(21, 1), return_sequences=True))\n",
    "model.add(LSTM(64, input_shape=(21,1)))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=10)\n",
    "\n",
    "model.save('../models/normalized_sentiments.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
