{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load the sample data to evaluate the model\n",
    "df = pd.read_csv(\"../data/GE.csv\")\n",
    "\n",
    "# add new column Open_before which contains the open values of the previous day\n",
    "df[\"Open_before\"] = df[\"Open\"].shift(1)\n",
    "\n",
    "# calculate the procentual change of the open value of the current day to the \n",
    "# open value of the day before\n",
    "df[\"Open_changes\"] = (df[\"Open\"] / df[\"Open_before\"]) - 1\n",
    "\n",
    "# throw out the first line which has NaN as value because of the previous shift of values \n",
    "df = df.dropna()\n",
    "\n",
    "# reset index to start by 0\n",
    "df.index -= 1\n",
    "\n",
    "changes = df[\"Open_changes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11614, 1)\n",
      "[[-0.00833331]\n",
      " [-0.005042  ]\n",
      " [-0.01182429]\n",
      " ...\n",
      " [-0.01475702]\n",
      " [ 0.00910426]\n",
      " [-0.01891735]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# normalize data\n",
    "\n",
    "# border to split in test and training data\n",
    "split_border = int(len(changes) * 0.8)\n",
    "\n",
    "# build test and training data\n",
    "train = np.array(changes[:split_border]).reshape(-1, 1)\n",
    "test = np.array(changes[split_border:]).reshape(-1, 1)\n",
    "\n",
    "print(train.shape)\n",
    "print(train)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# train the scaler with training data and smooth data\n",
    "smoothing_window_size = 2500\n",
    "for di in range(0, 10000, smoothing_window_size):\n",
    "    scaler.fit(train[di:di+smoothing_window_size,:])\n",
    "    train[di:di+smoothing_window_size,:] = scaler.transform(train[di:di+smoothing_window_size,:])\n",
    "\n",
    "# normalize the rest of the data which is len(train) - 10000\n",
    "scaler.fit(train[di+smoothing_window_size:,:])\n",
    "train[di+smoothing_window_size:,:] = scaler.transform(train[di+smoothing_window_size:,:])\n",
    "\n",
    "# normalize test data\n",
    "test = scaler.transform(test)\n",
    "\n",
    "# reshape test and train data\n",
    "train = train.reshape(-1)\n",
    "test = test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform exponential moving average\n",
    "EMA = 0.0\n",
    "gamma = 0.1\n",
    "for ti in range(len(train)):\n",
    "    EMA = gamma * train[ti] + (1 - gamma) * EMA\n",
    "    train[ti] = EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Wie kriege ich aus den normalisierten Daten nun meine X und Y Daten im richtigen Format\n",
    "train_len = len(train)\n",
    "test_len = len(test)\n",
    "\n",
    "Y_train = np.array(train[:train_len-20])\n",
    "Y_test = np.array(test[:test_len-20])\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "# predict price with previous 20 entries\n",
    "for i in range(0, len(train) - 20):\n",
    "    X_train.append(np.array(train[i+1:i+21]))\n",
    "for i in range(0, len(test) - 20):\n",
    "    X_test.append(np.array(test[i+1:i+21]))\n",
    "\n",
    "# reshape training data\n",
    "X_train = np.array(X_train).reshape(-1, 20, 1)\n",
    "X_test = np.array(X_test).reshape(-1, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0907 14:27:29.034299 10588 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0907 14:27:29.072890 10588 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0907 14:27:29.075883 10588 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0907 14:27:29.650713 10588 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0907 14:27:29.943747 10588 deprecation.py:323] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0907 14:27:31.363215 10588 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0907 14:27:31.378996 10588 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11594/11594 [==============================] - 18s 2ms/step - loss: 0.0017\n",
      "Epoch 2/10\n",
      "11594/11594 [==============================] - 15s 1ms/step - loss: 5.7427e-04\n",
      "Epoch 3/10\n",
      "11594/11594 [==============================] - 15s 1ms/step - loss: 4.4054e-04\n",
      "Epoch 4/10\n",
      "11594/11594 [==============================] - 16s 1ms/step - loss: 3.9581e-04\n",
      "Epoch 5/10\n",
      " 4928/11594 [===========>..................] - ETA: 8s - loss: 3.4406e-04"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(20, 1), return_sequences=True))\n",
    "model.add(LSTM(64, input_shape=(20,1)))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=10)\n",
    "\n",
    "model.save('../models/multiple-layer-lstm-with-dense-with-normalization.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faktor um den das eingesetzte Vermögen steigt aktueller Stand / damaliger Stand \n",
    "# Berechne Rendite für Testdaten\n",
    "# An der Stelle split_border ist df[\"Open_changes\"] gleich Y_test[0]\n",
    "rendite = df[\"Open\"][14517] / df[\"Open\"][split_border]\n",
    "\n",
    "# Marktrendite bei 100 Euro Einsatz\n",
    "markt_return = 100 * rendite\n",
    "\n",
    "# Rendite bei Trading durch das Modell\n",
    "buy_or_sell = []\n",
    "\n",
    "# predictions of Neuronal Net\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predictions = np.array(predictions).reshape(-1)\n",
    "\n",
    "# True when buy stock, false when sell stock\n",
    "for change in predictions: \n",
    "    if change > 0:\n",
    "        buy_or_sell.append(True)\n",
    "    else:\n",
    "        buy_or_sell.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne Rendite bei Neuronalem Netz\n",
    "# 1. Iteriere über buy_or_sell\n",
    "# 2. Wenn prediction True dann kaufe Aktie zu diesem Zeitpunkt \n",
    "# 3. Wenn prediction False dann verkaufe alle Aktien\n",
    "\n",
    "# starte mit kapital von 100 Euro\n",
    "kapital = 100\n",
    "# Anzahl Aktien im Depot\n",
    "depot = 0\n",
    "# Kurs in Euro pro Aktie\n",
    "kurs = 0\n",
    "\n",
    "# Annahme: Investiere immer das komplette Kapital bzw verkaufe komplettes Depot\n",
    "for (prediction, i) in zip(buy_or_sell, range(split_border, 14518 - 20)):\n",
    "    if prediction == True and kapital > 0:\n",
    "        # kaufe Aktie zum Zeitpunkt i\n",
    "        kurs = df[\"Open\"][i]\n",
    "        # depot[Aktien] = Kapital[Euro] * (1 [Aktie] / Kurs [Euro pro Aktie])\n",
    "        depot += kapital * (1 / kurs)\n",
    "        kapital = 0\n",
    "    elif depot > 0:\n",
    "        # verkaufe Aktien im Depot zum Zeitpunkt i\n",
    "        kurs = df[\"Open\"][i]\n",
    "        kapital = depot * kurs \n",
    "        depot = 0\n",
    "\n",
    "print(kapital)\n",
    "print(markt_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
