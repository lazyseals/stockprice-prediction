{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pw0J0Fcfh5cs"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once per notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 85281,
     "status": "ok",
     "timestamp": 1568737562035,
     "user": {
      "displayName": "Daniel von Mirbach",
      "photoUrl": "",
      "userId": "14196858848142309309"
     },
     "user_tz": -60
    },
    "id": "Sak0p36Li71h",
    "outputId": "92d6ce52-2bfc-45ee-bbeb-a3da15d012a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 files were uploaded in /root/data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# choose a local (colab) directory to store the data.\n",
    "local_root_path = os.path.expanduser(\"~/data\")\n",
    "try:\n",
    "  os.makedirs(local_root_path)\n",
    "except: pass\n",
    "\n",
    "def ListFolder(google_drive_id, destination):\n",
    "  file_list = drive.ListFile({'q': \"'%s' in parents and trashed=false\" % google_drive_id}).GetList()\n",
    "  counter = 0\n",
    "  for f in file_list:\n",
    "    # If it is a directory then, create the dicrectory and upload the file inside it\n",
    "    if f['mimeType']=='application/vnd.google-apps.folder': \n",
    "      folder_path = os.path.join(destination, f['title'])\n",
    "      os.makedirs(folder_path)\n",
    "      print('creating directory {}'.format(folder_path))\n",
    "      ListFolder(f['id'], folder_path)\n",
    "    else:\n",
    "      fname = os.path.join(destination, f['title'])\n",
    "      f_ = drive.CreateFile({'id': f['id']})\n",
    "      f_.GetContentFile(fname)\n",
    "      counter += 1\n",
    "  print('{} files were uploaded in {}'.format(counter, destination))\n",
    "\n",
    "ListFolder(\"1Ze3XcYI__VI638idIf30g_v0SaaBm1YQ\", local_root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86919,
     "status": "ok",
     "timestamp": 1568737564106,
     "user": {
      "displayName": "Daniel von Mirbach",
      "photoUrl": "",
      "userId": "14196858848142309309"
     },
     "user_tz": -60
    },
    "id": "2JBEb5hAjHSY",
    "outputId": "5683400b-669a-4f71-ed58-bdf10491bc23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from requests import get\n",
    "import json\n",
    "import re \n",
    "from textblob import TextBlob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87029,
     "status": "ok",
     "timestamp": 1568737564751,
     "user": {
      "displayName": "Daniel von Mirbach",
      "photoUrl": "",
      "userId": "14196858848142309309"
     },
     "user_tz": -60
    },
    "id": "ywLyTC5FjzxR",
    "outputId": "4aeb874a-f824-4241-c55b-5e6717a37d15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0917 19:34:38.016858 12868 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0917 19:34:38.079162 12868 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0917 19:34:38.094513 12868 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0917 19:34:39.338060 12868 deprecation_wrapper.py:119] From C:\\Users\\Daniel\\.conda\\envs\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(21,1), return_sequences=True))\n",
    "model.add(LSTM(64, input_shape=(21,1)))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34784,
     "status": "error",
     "timestamp": 1568720500215,
     "user": {
      "displayName": "Daniel von Mirbach",
      "photoUrl": "",
      "userId": "14196858848142309309"
     },
     "user_tz": -60
    },
    "id": "2oYe-n35jMiF",
    "outputId": "0e6b8a9e-00a6-4f43-8596-9680af6fc1de"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Das System kann den angegebenen Pfad nicht finden: '/root/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-59f52ab43677>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load all stock files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m files = [f for f in listdir(\"/root/data\") if isfile(\n\u001b[0m\u001b[0;32m      3\u001b[0m     join(\"/root/data\", f))]\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# iterate stock files for building and training model model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Das System kann den angegebenen Pfad nicht finden: '/root/data'"
     ]
    }
   ],
   "source": [
    "# load all stock files\n",
    "files = [f for f in listdir(\"../data/dow_jones_stocks\") if isfile(\n",
    "    join(\"/root/data\", f))]\n",
    "\n",
    "# iterate stock files for building and training model model\n",
    "for file in files:\n",
    "    # source path to train data\n",
    "    source_file_path = \"/root/data/\" + file\n",
    "    \n",
    "    # read in data as df\n",
    "    df = pd.read_csv(source_file_path)\n",
    "    \n",
    "    # add new column Open_before which contains the open values of the previous day\n",
    "    df[\"Open_before\"] = df[\"Open\"].shift(1)\n",
    "\n",
    "    # calculate the procentual change of the open value of the current day to the \n",
    "    # open value of the day before\n",
    "    df[\"Open_changes\"] = (df[\"Open\"] / df[\"Open_before\"]) - 1\n",
    "\n",
    "    # throw out the first line which has NaN as value because of the previous shift of values \n",
    "    df = df.dropna()\n",
    "\n",
    "    # reset index to start by 0\n",
    "    df.index -= 1\n",
    "\n",
    "    changes = df[\"Open_changes\"]\n",
    "    sentiments = df[\"Sentiment\"]\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    # resort data frame by start backwards\n",
    "    df = df[::-1]\n",
    "\n",
    "    # X data with additional value for the sentiment\n",
    "    for i in range(0, len(changes)- 20):\n",
    "        try:\n",
    "            Y.append(changes[i])\n",
    "            to_add = changes[i+1:i+21].tolist()\n",
    "            to_add.append(sentiments[i])\n",
    "            X.append(to_add)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # border to split in test and training data\n",
    "    split_border = int(len(X) * 0.8)\n",
    "\n",
    "    # build test and training data\n",
    "    X_train = np.array(X[:split_border]).reshape(-1, 21, 1)\n",
    "    X_test = np.array(X[split_border:]).reshape(-1, 21, 1)\n",
    "    Y_train = np.array(Y[:split_border])\n",
    "    Y_test = np.array(Y[split_border:])\n",
    "    \n",
    "    # train model\n",
    "    model.fit(X_train, Y_train, batch_size=32, epochs=10)\n",
    "    \n",
    "    # print out which stock is done\n",
    "    print(file + \" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eOpBW6RlXU1"
   },
   "outputs": [],
   "source": [
    "model.save('./multiple-layer-with-sentiments-dow-jones.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfZsEDC_zSdu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "multiple-layer-with-sentiments-dow-jones.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
